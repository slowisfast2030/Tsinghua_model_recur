{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator是tensorflow高度封装的一个类，里面有一些可以直接使用的分类和回归模型，    \n",
    "例如tf.estimator.DNNClassifier，但这不是这篇博客的主题，而是怎么使用estimator来实现我们自定义模型的训练。    \n",
    "它的步骤主要分为以下几个部分：\n",
    "* 构建model_fn，在这个方法里面定义自己的模型以及训练和测试过程要做的事情；\n",
    "* 构建input_fn，在这个方法数据的来源和喂给模型的方式；\n",
    "* 最后，创建estimator对象，然后开始训练模型了。可以添加一些config，比如：loss的输出频率等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建model_fn方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):  # 必须要有前面三个参数\n",
    "    # feature和labels其实就是`input_fn`方法传输过来的\n",
    "    # mode是用来判断你现在是训练或测试阶段\n",
    "    # params是在创建`estimator`对象的输入参数\n",
    "    lr = params['lr']\n",
    "    try:\n",
    "        init_checkpoint = params['init_checkpoint']\n",
    "    except KeyError:\n",
    "        init_checkpoint = None\n",
    "\n",
    "\n",
    "    x = features['inputs']\n",
    "    y = features['labels']\n",
    "\n",
    "    #####################在这里定义你自己的网络模型###################\n",
    "    pre = tf.layers.dense(x, 1)\n",
    "    loss = tf.reduce_mean(tf.pow(pre-y, 2), name='loss')\n",
    "    ######################在这里定义你自己的网络模型###################\n",
    "\n",
    "    # 这里可以加载你的预训练模型\n",
    "    assignment_map = dict()\n",
    "    if init_checkpoint:\n",
    "        for var in tf.train.list_variables(init_checkpoint):  # 存放checkpoint的变量名称和shape\n",
    "            assignment_map[var[0]] = var[0]\n",
    "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "\n",
    "    # 定义你训练过程要做的事情\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        output_spec = tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # 定义你测试（验证）过程\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        metrics = {'eval_loss': tf.metrics.mean_tensor(loss), \"accuracy\": tf.metrics.accuracy(labels, pre)}\n",
    "        output_spec = tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # 定义你的预测过程\n",
    "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {'predictions': pre}\n",
    "        output_spec = tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    else:\n",
    "        raise TypeError\n",
    "\n",
    "    return output_spec\n",
    "\n",
    "'''\n",
    "提几点需要注意的地方： \n",
    "1. model_fn方法返回的是tf.estimator.EstimatorSpec; \n",
    "2. TRAIN、EVAL和PREDICT模式不可缺少的参数是不一样的。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建input_fn方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_bulider(inputs_file, batch_size, is_training):\n",
    "    name_to_features = {'inputs': tf.FixedLenFeature([3], tf.float32),\n",
    "                        'labels': tf.FixedLenFeature([], tf.float32)}\n",
    "\n",
    "    def input_fn(params): \n",
    "        d = tf.data.TFRecordDataset(inputs_file)\n",
    "        if is_training:\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle()\n",
    "\n",
    "        # map_and_batch其实就是将map和batch结合起来而已\n",
    "        d = d.apply(tf.contrib.data.map_and_batch(lambda x: tf.parse_single_example(x, name_to_features), \n",
    "                                                   batch_size=batch_size))\n",
    "        return d\n",
    "\n",
    "    return input_fn\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 执行eatimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main':\n",
    "    # 定义日志消息的输出级别，为了获取模型的反馈信息，选择INFO\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    # 我在这里是指定模型的保存和loss输出频率\n",
    "    runConfig = tf.estimator.RunConfig(save_checkpoints_steps=1,\n",
    "                                       log_step_count_steps=1)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(model_fn, model_dir='your_save_path',\n",
    "                                       config=runConfig, params={'lr': 0.01})\n",
    "\n",
    "    # log_step_count_steps控制的只是loss的global_step的输出\n",
    "    # 我们还可以通过tf.train.LoggingTensorHook自定义更多的输出\n",
    "    # tensor是我们要输出的内容，输入一个字典，key为打印出来的名称，value为你要输出的tensor的name\n",
    "    logging_hook = tf.train.LoggingTensorHook(every_n_iter=1,\n",
    "                                              tensors={'loss': 'loss'})\n",
    "\n",
    "    # 其实给到estimator.train是一个dataset对象\n",
    "    input_fn = input_fn_bulider('test.tfrecord', batch_size=1, is_training=True)\n",
    "    estimator.train(input_fn, max_steps=1000)\n",
    "    # 下面你还可以对模型进行验证和测试，做法是差不多的，我就不列举了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('tsinghua')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a7b5a4626d32b8252d3636695c99eb70559e5b3a83ef0cdb9ac852ddf775b11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
